{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ts_data = pd.read_parquet('../data/transformed/ts_data_2022_01.parquet')\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data_one_location = ts_data.loc[ts_data.pickup_location_id == 43, :].reset_index(drop=True)\n",
    "ts_data_one_location = ts_data_one_location.sort_values(by = \"pickup_hour\")\n",
    "ts_data_one_location.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cutoff_indices(\n",
    "    data: pd.DataFrame,\n",
    "    n_features: int,\n",
    "    step_size: int\n",
    "    ) -> list:\n",
    "\n",
    "        stop_position = len(data) - 1\n",
    "        \n",
    "        # Start the first sub-sequence at index position 0\n",
    "        subseq_first_idx = 0\n",
    "        subseq_mid_idx = n_features\n",
    "        subseq_last_idx = n_features + 1\n",
    "        indices = []\n",
    "        \n",
    "        while subseq_last_idx <= stop_position:\n",
    "            indices.append((subseq_first_idx, subseq_mid_idx, subseq_last_idx))\n",
    "            \n",
    "            subseq_first_idx += step_size\n",
    "            subseq_mid_idx += step_size\n",
    "            subseq_last_idx += step_size\n",
    "\n",
    "        return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 24\n",
    "step_size = 1\n",
    "\n",
    "indices = get_cutoff_indices(\n",
    "    ts_data_one_location,\n",
    "    n_features,\n",
    "    step_size\n",
    ")\n",
    "indices[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_examples = len(indices)\n",
    "x = np.ndarray(shape=(n_examples, n_features), dtype=np.float32)\n",
    "y = np.ndarray(shape=(n_examples), dtype=np.float32)\n",
    "pickup_hours = []\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    x[i, :] = ts_data_one_location.iloc[idx[0]:idx[1]]['rides'].values\n",
    "    y[i] = ts_data_one_location.iloc[idx[1]:idx[2]]['rides'].values\n",
    "    pickup_hours.append(ts_data_one_location.iloc[idx[1]]['pickup_hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{x.shape=}')\n",
    "print(f'{x=}')\n",
    "print(f'{pickup_hours[:5]=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_one_location = pd.DataFrame(\n",
    "    x,\n",
    "    columns=[f'rides_previous_{i+1}_hour' for i in reversed(range(n_features))]\n",
    ")\n",
    "features_one_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_one_location = pd.DataFrame(y, columns=[f'target_rides_next_hour'])\n",
    "targets_one_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def transform_ts_data_into_features_and_target(\n",
    "    ts_data: pd.DataFrame,\n",
    "    input_seq_len: int,\n",
    "    step_size: int\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Slices and transposes data from time-series format into a (features, target)\n",
    "    format that we can use to train Supervised ML models\n",
    "    \"\"\"\n",
    "    assert set(ts_data.columns) == {'pickup_hour', 'rides', 'pickup_location_id'}\n",
    "\n",
    "    location_ids = ts_data['pickup_location_id'].unique()\n",
    "    features = pd.DataFrame()\n",
    "    targets = pd.DataFrame()\n",
    "    \n",
    "    for location_id in tqdm(location_ids):\n",
    "        \n",
    "        # keep only ts data for this `location_id`\n",
    "        ts_data_one_location = ts_data.loc[\n",
    "            ts_data.pickup_location_id == location_id, \n",
    "            ['pickup_hour', 'rides']\n",
    "        ]\n",
    "        \n",
    "        ts_data_one_location = ts_data_one_location.sort_values(by = \"pickup_hour\")\n",
    "\n",
    "        # pre-compute cutoff indices to split dataframe rows\n",
    "        indices = get_cutoff_indices(\n",
    "            ts_data_one_location,\n",
    "            input_seq_len,\n",
    "            step_size\n",
    "        )\n",
    "\n",
    "        # slice and transpose data into numpy arrays for features and targets\n",
    "        n_examples = len(indices)\n",
    "        x = np.ndarray(shape=(n_examples, input_seq_len), dtype=np.float32)\n",
    "        y = np.ndarray(shape=(n_examples), dtype=np.float32)\n",
    "        pickup_hours = []\n",
    "        for i, idx in enumerate(indices):\n",
    "            x[i, :] = ts_data_one_location.iloc[idx[0]:idx[1]]['rides'].values\n",
    "            y[i] = ts_data_one_location.iloc[idx[1]:idx[2]]['rides'].values\n",
    "            pickup_hours.append(ts_data_one_location.iloc[idx[1]]['pickup_hour'])\n",
    "\n",
    "        # numpy -> pandas\n",
    "        features_one_location = pd.DataFrame(\n",
    "            x,\n",
    "            columns=[f'rides_previous_{i+1}_hour' for i in reversed(range(input_seq_len))]\n",
    "        )\n",
    "        features_one_location['pickup_hour'] = pickup_hours\n",
    "        features_one_location['pickup_location_id'] = location_id\n",
    "\n",
    "        # numpy -> pandas\n",
    "        targets_one_location = pd.DataFrame(y, columns=[f'target_rides_next_hour'])\n",
    "\n",
    "        # concatenate results\n",
    "        features = pd.concat([features, features_one_location])\n",
    "        targets = pd.concat([targets, targets_one_location])\n",
    "\n",
    "    features.reset_index(inplace=True, drop=True)\n",
    "    targets.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    return features, targets['target_rides_next_hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, targets = transform_ts_data_into_features_and_target(\n",
    "    ts_data,\n",
    "    input_seq_len=24*7*1, # one week of history\n",
    "    step_size=24,\n",
    ")\n",
    "\n",
    "print(f'{features.shape=}')\n",
    "print(f'{targets.shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b98d97558a062384a76b0309256306c9ce5dd4e2074fe66c33532239207fc923"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
